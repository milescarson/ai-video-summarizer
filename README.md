# PR Review AI

LLM-Powered GitHub Pull Request Review Assistant - A production-grade tool that analyzes GitHub pull requests using AI and provides structured, actionable code reviews.

## üöÄ Overview

This application allows users to:

- Paste a public GitHub Pull Request URL
- Fetch the PR diff using the GitHub API
- Analyze the diff using an LLM (OpenAI GPT-4) acting as a senior code reviewer
- Display a structured, readable review with risk categorization

Built as a portfolio project demonstrating clean architecture, modern TypeScript practices, and full-stack development skills.

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Frontend                            ‚îÇ
‚îÇ  (Vite + React + TypeScript + shadcn/ui + TailwindCSS)    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  UI Layer    ‚îÇ  ‚îÇ React Query  ‚îÇ  ‚îÇ  Zustand Store  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (Components) ‚îÇ  ‚îÇ  (API State) ‚îÇ  ‚îÇ  (Local State)  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ            ‚îÇ               ‚îÇ                   ‚îÇ            ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                            ‚îÇ                                ‚îÇ
‚îÇ                      [Axios Client]                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                    HTTP POST /api/review
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Backend                             ‚îÇ
‚îÇ        (Node.js + Express + TypeScript + Octokit)          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Controller  ‚îÇ‚Üí ‚îÇ   Services   ‚îÇ‚Üí ‚îÇ   External APIs ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Routing)   ‚îÇ  ‚îÇ  (Business   ‚îÇ  ‚îÇ  - GitHub API   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ    Logic)    ‚îÇ  ‚îÇ  - OpenAI/Gemini‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                  ‚îÇ                   ‚îÇ            ‚îÇ
‚îÇ    [Validation]      [Processing]       [Integration]      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

1. **User Input**: User submits GitHub PR URL via frontend form
2. **Validation**: Zod schema validates URL format on both client and server
3. **PR Parsing**: Backend extracts owner, repo, and PR number
4. **GitHub API**: Fetch PR metadata and file diffs using Octokit
5. **Diff Processing**: Normalize and chunk diff data for LLM consumption
6. **Provider Selection**: Factory creates appropriate LLM provider (OpenAI or Gemini)
7. **LLM Analysis**: Send diff to selected provider with structured prompt
8. **Response Parsing**: Parse JSON response from LLM
9. **UI Rendering**: Display categorized review results

## üì¶ Tech Stack

### Frontend

- **Vite**: Fast build tool and dev server
- **React 18**: UI library with hooks
- **TypeScript**: Type safety throughout
- **shadcn/ui**: High-quality Radix + Tailwind components
- **TailwindCSS**: Utility-first styling
- **Zustand**: Lightweight state management
- **React Query (TanStack Query)**: Server state management
- **Axios**: HTTP client
- **Zod**: Runtime schema validation

### Backend

- **Node.js + TypeScript**: Runtime and language
- **Express**: Web framework
- **Octokit**: Official GitHub REST API client
- **LLM Providers**:
  - **OpenAI SDK**: GPT-4 Turbo integration
  - **Google Generative AI**: Gemini 1.5 Pro integration
- **Factory Pattern**: Extensible provider abstraction
- **Zod**: Request validation
- **dotenv**: Environment configuration
- **ESLint + Prettier**: Code quality

## üéØ Prompt Design

The LLM prompt is carefully engineered for high-quality code reviews:

### System Prompt

```
You are a senior software engineer performing a pull request review.

Rules:
- Only comment on what is visible in the diff.
- Do NOT assume missing context.
- If something is unclear, ask a question instead of guessing.
- Be strict, constructive, and practical.
- Focus on bugs, edge cases, performance, security, and maintainability.
```

### Response Structure

The LLM returns structured JSON with six categories:

- **Summary**: High-level overview of changes
- **High Risk Issues**: Critical bugs, security vulnerabilities
- **Medium Risk Issues**: Logic errors, potential bugs
- **Low Risk / Style Issues**: Code style, minor improvements
- **Suggestions**: Best practices, optimizations
- **Questions for Author**: Clarifications needed

### Why This Design?

1. **Strict Rules**: Prevents hallucination by limiting analysis to visible code
2. **Risk Categorization**: Helps prioritize reviewer attention
3. **JSON Format**: Ensures structured, parseable output
4. **Constructive Tone**: Balances strictness with helpfulness
5. **Question Section**: Acknowledges uncertainty rather than guessing

## üìÇ Project Structure

```
pr-review-ai/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.ts                    # Express app setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.ts                 # Server entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ env.ts                # Environment validation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review.route.ts       # API routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review.controller.ts  # Request handlers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.ts           # LLM provider interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai.provider.ts # OpenAI implementation
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini.provider.ts # Gemini implementation
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ factory.ts        # Provider factory
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts          # Exports
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github.service.ts     # GitHub API integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.service.ts        # LLM service layer
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review.service.ts     # Core business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parsePrUrl.ts         # URL parsing utility
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunkDiff.ts          # Diff processing
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.ts             # Logging utility
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review.schema.ts      # Zod validation schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ review.ts             # TypeScript interfaces
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îÇ
‚îî‚îÄ‚îÄ frontend/
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ app/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx               # Main application
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ providers/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ query-client.tsx  # React Query setup
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ index.tsx         # Provider composition
    ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ review/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReviewResult.tsx  # Main review display
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReviewSection.tsx # Section wrapper
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ IssueList.tsx     # Issue rendering
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                   # shadcn components
    ‚îÇ   ‚îú‚îÄ‚îÄ features/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ api.ts            # API client functions
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ schema.ts         # Client validation
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ store.ts          # Zustand store
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ types.ts          # TypeScript types
    ‚îÇ   ‚îú‚îÄ‚îÄ lib/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ axios.ts              # Axios configuration
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.ts              # Utility functions
    ‚îÇ   ‚îú‚îÄ‚îÄ styles/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ globals.css           # Global styles
    ‚îÇ   ‚îî‚îÄ‚îÄ main.tsx                  # Application entry
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ vite.config.ts
    ‚îú‚îÄ‚îÄ tailwind.config.js
    ‚îî‚îÄ‚îÄ .env.example
```

## üõ†Ô∏è Setup Instructions

### Prerequisites

- Node.js 18+ and yarn
- LLM Provider API Key (choose one):
  - OpenAI API key (for GPT-4)
  - Google AI API key (for Gemini)
- GitHub Personal Access Token (optional, increases rate limits)

### Backend Setup

1. Navigate to backend directory:

```bash
cd backend
```

2. Install dependencies:

```bash
yarn install
```

3. Create `.env` file:

```bash
cp .env.example .env
```

4. Configure environment variables in `.env`:

**Option A: Using OpenAI (GPT-4)**

```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-key-here
GITHUB_TOKEN=ghp_your-github-token-here  # Optional but recommended
PORT=4000
NODE_ENV=development
```

**Option B: Using Google Gemini**

```env
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-gemini-api-key-here
GITHUB_TOKEN=ghp_your-github-token-here  # Optional but recommended
PORT=4000
NODE_ENV=development
```

> **Note**: The `LLM_PROVIDER` field determines which AI service to use. Set it to either `openai` or `gemini`, and provide the corresponding API key.

5. Start development server:

```bash
yarn dev
```

Backend will run at `http://localhost:4000`

### Frontend Setup

1. Navigate to frontend directory:

```bash
cd frontend
```

2. Install dependencies:

```bash
yarn install
```

3. Create `.env` file:

```bash
cp .env.example .env
```

4. Configure environment (defaults work for local development):

```env
VITE_API_BASE_URL=http://localhost:4000
```

5. Start development server:

```bash
yarn dev
```

Frontend will run at `http://localhost:5173`

### Full Stack Development

Run both servers concurrently in separate terminals for full-stack development.

## üéÆ Usage

1. Open the frontend in your browser: `http://localhost:5173`
2. Paste a public GitHub PR URL (e.g., `https://github.com/facebook/react/pull/28000`)
3. Click "Review PR"
4. Wait 10-30 seconds for analysis
5. View structured review with categorized findings

### Example PR to Test

```
https://github.com/vercel/next.js/pull/59000
https://github.com/microsoft/vscode/pull/200000
https://github.com/facebook/react/pull/28000
```

Note: PR must be from a public repository.

## ‚öôÔ∏è Environment Variables

### Backend

| Variable         | Description                   | Required       |
| ---------------- | ----------------------------- | -------------- |
| `OPENAI_API_KEY` | OpenAI API key for LLM access | ‚úÖ Yes         |
| `GITHUB_TOKEN`   | GitHub personal access token  | ‚ö†Ô∏è Recommended |
| `PORT`           | Server port (default: 4000)   | ‚ùå No          |
| `NODE_ENV`       | Environment mode              | ‚ùå No          |

### Frontend

| Variable            | Description     | Required |
| ------------------- | --------------- | -------- |
| `VITE_API_BASE_URL` | Backend API URL | ‚úÖ Yes   |

## üöß Error Handling

The application handles various error scenarios gracefully:

- **Invalid URL Format**: Client-side Zod validation
- **Private Repositories**: GitHub API returns 404
- **Rate Limiting**: GitHub/OpenAI API rate limits
- **Network Errors**: Axios interceptors with user-friendly messages
- **LLM Failures**: Fallback error responses
- **Large Diffs**: Automatic truncation at 8000 characters

All errors display user-friendly messages without exposing stack traces.

## üé® Code Quality Features

- **Strict TypeScript**: No `any` types, full type safety
- **Functional Architecture**: Pure functions, clear separation of concerns
- **No Logic in JSX**: Components only handle rendering
- **Validation Everywhere**: Zod schemas on client and server
- **ESLint + Prettier**: Consistent code formatting
- **Clear Naming**: No abbreviations, self-documenting code
- **Small Functions**: Most functions under 50 lines
- **Error Boundaries**: Graceful error handling throughout

## üîÑ Tradeoffs & Limitations

### Current Limitations

1. **Public PRs Only**: Cannot access private repositories without OAuth
2. **Diff Size**: Large PRs truncated at 8000 chars to manage token limits
3. **Single File Processing**: All files analyzed together (not individually)
4. **No Persistence**: Reviews not saved (stateless design)
5. **Rate Limits**: Subject to GitHub (5000/hour) and OpenAI limits

### Design Decisions

- **No Database**: Keeps architecture simple, suitable for demo/portfolio
- **Synchronous Processing**: Simpler than async job queues for MVP
- **Client-Side State**: Zustand sufficient for single-page app
- **Monorepo Structure**: Separate backend/frontend for clarity

## üöÄ Future Improvements

### Short Term

- [ ] Add loading skeleton UI
- [ ] Support PR comparison (base vs head)
- [ ] Add "copy review" functionality
- [ ] Dark mode toggle
- [ ] Review history (local storage)

### Medium Term

- [ ] OAuth for private repositories
- [ ] Batch file analysis for large PRs
- [ ] Configurable LLM parameters (temperature, model)
- [ ] Export review as Markdown/PDF
- [ ] Multiple LLM provider support (Anthropic, etc.)

### Long Term

- [ ] User authentication and saved reviews
- [ ] GitHub App integration (webhook-based)
- [ ] Real-time streaming responses
- [ ] Custom review templates
- [ ] Team analytics dashboard

## üìä Example Output

```json
{
  "summary": "This PR introduces a new authentication system using JWT tokens...",
  "high_risk_issues": [
    "Line 42: JWT secret is hardcoded. Use environment variables.",
    "Line 78: SQL query vulnerable to injection. Use parameterized queries."
  ],
  "medium_risk_issues": [
    "Line 120: Error handling missing for async operation."
  ],
  "low_risk_or_style_issues": ["Line 15: Consider using const instead of let."],
  "suggestions": ["Consider adding unit tests for the new auth middleware."],
  "questions_for_author": [
    "What is the expected behavior when the token expires?"
  ]
}
```

## üß™ Testing

### Manual Testing

1. Test with various PR sizes (small, medium, large)
2. Test with different programming languages
3. Test error scenarios (invalid URL, private repo, rate limits)
4. Test edge cases (empty PR, binary files, etc.)

### Automated Testing (Future)

- Unit tests for utils and services
- Integration tests for API endpoints
- E2E tests for critical user flows

## üìù License

MIT License - feel free to use this project for learning or portfolio purposes.

## ü§ù Contributing

This is a portfolio project, but feedback and suggestions are welcome! Open an issue or submit a PR.

## üë®‚Äçüíª Author

Built as a demonstration of production-grade full-stack development skills.

---

**Note**: This project is designed for educational and portfolio purposes. For production use, consider adding authentication, database persistence, and more robust error handling.
